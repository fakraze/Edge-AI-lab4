# Edge-AI Lab 4: YOLOv8 Model Pruning for Edge Deployment

This project implements YOLOv8 instance segmentation model pruning using PyTorch-based structured pruning techniques. The goal is to reduce model size and computational complexity while maintaining acceptable performance for edge AI deployment.

## ğŸ¬ Demo & Results

- **ğŸ“º Demo Video**: [Watch on YouTube](https://www.youtube.com/watch?v=MsMMYl46mtQ)

## ğŸ¯ Final Approach

> **Important**: The pruning results were not ideal for our deployment requirements. Therefore, our final implementation uses **YOLOv8n-seg + INT8 quantization** as the optimal approach for edge deployment.

> ** Documentation**: For detailed implementation analysis and results, please refer to the report PDF file.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Features](#features)
- [Performance Results](#performance-results)
- [Environment Setup](#environment-setup)
- [Dataset Preparation](#dataset-preparation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Troubleshooting](#troubleshooting)
- [References](#references)

## ğŸ¯ Project Overview

This project demonstrates structured pruning of YOLOv8 instance segmentation models using torch-pruning library. The implementation includes:

- **Iterative structured pruning** with gradual sparsity increase
- **Fine-tuning** after each pruning step to recover performance
- **Performance monitoring** with mAP tracking
- **Model export** to ONNX format for deployment

## âœ¨ Features

- ğŸ”¥ **Structured Pruning**: Uses torch-pruning for channel-wise pruning
- ğŸ“Š **Performance Tracking**: Monitors mAP changes throughout pruning process
- ğŸ¯ **Configurable**: Flexible pruning parameters via YAML configuration
- ğŸ’¾ **Model Export**: Exports pruned models to ONNX format
- ğŸ“ˆ **Visualization**: Generates performance graphs and charts
- ğŸ”„ **Iterative Process**: Gradual pruning with fine-tuning steps

## ğŸ“ˆ Performance Results

| Metric | Original | Pruned | Change |
|--------|----------|---------|--------|
| **Model Size** | 3.41M params | 2.13M params | -37.6% |
| **MACs** | 6.36G | 4.62G | -27.3% |
| **Box mAP@0.5:0.95** | 0.364 | 0.275 | -24.5% |
| **Mask mAP@0.5:0.95** | 0.306 | 0.229 | -25.2% |
| **Speed Improvement** | 1x | 1.38x | +37.5% |

*Pruning ratio: 24% with target rate: 30%*

## ğŸ› ï¸ Environment Setup

### 1. Create Virtual Environment

```bash
python3 -m venv yolov8_2
source yolov8_2/bin/activate
```

### 2. Install Dependencies

```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install pruning and other dependencies
pip install torch-pruning numpy pyyaml
```

### 3. Install Ultralytics (Legacy Version)

```bash
mkdir repo
cd repo
git clone https://github.com/ultralytics/ultralytics.git
cd ultralytics
git checkout -b legacy-v8.0.114 tags/v8.0.114
python -m pip uninstall ultralytics -y
python -m pip install -e .
```

## ğŸ“ Dataset Preparation

### COCO Dataset Setup

The project uses COCO 2017 dataset for training and validation.

#### Tutorial Reference
- ğŸ“– [Ultralytics COCO Dataset Documentation](https://docs.ultralytics.com/datasets/detect/coco/)

#### Automatic Dataset Download

The COCO dataset will be automatically downloaded during the first training run:

```bash
# This command will train yolo11n.pt and automatically download COCO datasets
yolo detect train data=coco.yaml model=yolo11n.pt epochs=100 imgsz=640
```

> **Note**: The dataset download is approximately 20.1 GB and will be placed in the `../datasets/coco` directory relative to your workspace.

#### Dataset Structure

After download, the dataset structure will be:

```
datasets/
â”œâ”€â”€ coco/                        # COCO 2017 dataset (20.1 GB)
â”‚   â”œâ”€â”€ LICENSE                  # Dataset license
â”‚   â”œâ”€â”€ README.txt              # Dataset information
â”‚   â”œâ”€â”€ images/                 # Image files
â”‚   â”‚   â”œâ”€â”€ train2017/          # Training images (118,287 images)
â”‚   â”‚   â”œâ”€â”€ val2017/            # Validation images (5,000 images)
â”‚   â”‚   â””â”€â”€ test2017/           # Test images (40,670 images)
â”‚   â”œâ”€â”€ labels/                 # Label files for segmentation
â”‚   â”‚   â”œâ”€â”€ train2017/          # Training labels
â”‚   â”‚   â””â”€â”€ val2017/            # Validation labels
â”‚   â”œâ”€â”€ annotations/            # COCO annotation files
â”‚   â”œâ”€â”€ train2017.txt          # Training image list
â”‚   â”œâ”€â”€ val2017.txt            # Validation image list
â”‚   â””â”€â”€ test-dev2017.txt       # Test image list
â”œâ”€â”€ coco128-seg/               # Smaller subset for testing (optional)
â”‚   â”œâ”€â”€ LICENSE
â”‚   â”œâ”€â”€ README.txt
â”‚   â”œâ”€â”€ images/                # 128 sample images
â”‚   â””â”€â”€ labels/                # Corresponding labels
â””â”€â”€ coco2017labels-segments.zip  # Segmentation labels archive
```

## ğŸš€ Usage

### 1. Model Pruning

Run the iterative pruning process:

```bash
source yolov8_2/bin/activate

python yolov8_pruning_origin.py \
    --model yolov8n-seg.pt \
    --cfg pruning_default.yaml \
    --iterative-steps 10 \
    --target-prune-rate 0.3 \
    --max-map-drop 1
```

> **Note**: Additional hyperparameters such as batch size, epochs, and dataset configuration are defined in `pruning_default.yaml`.


### 2. Fine-tuning

Fine-tune the pruned model:

```bash
python finetune_yolov8.py \
    --model runs/segment/step_7_finetune/weights/best.pt \
    --data coco.yaml \
    --epochs 30 \
    --train-batch 32 \
    --val-batch 8 \
    --imgsz 640 \
    --lr 1e-3 \
    --device 0,1 \
    --project finetune \
    --name step_8 \
    --save-period 1 \
    --workers 2
```

### 3. Model Export

Export pruned model to ONNX:

```bash
python output_onnx.py --model path/to/pruned_model.pt --output model_pruned.onnx
```

### Configuration Files

**pruning_default.yaml**: Main pruning configuration
```yaml
data: coco.yaml
batch: 16
val_batch: 8
imgsz: 640
epochs: 4
save_period: 1
name: yolov8n-seg-pruning
```

## ğŸ“‚ Project Structure

```
lab4/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ yolov8_pruning_origin.py    # Main pruning implementation
â”œâ”€â”€ yolov8_pruning.py           # Alternative pruning script
â”œâ”€â”€ finetune_yolov8.py          # Fine-tuning script
â”œâ”€â”€ output_onnx.py              # ONNX export utility
â”œâ”€â”€ coco.yaml                   # Dataset configuration
â”œâ”€â”€ pruning_default.yaml        # Pruning parameters
â”œâ”€â”€ note.txt                    # Development notes
â”œâ”€â”€ env.txt                     # Environment setup guide
â”œâ”€â”€ yolov8n-seg.pt             # Pre-trained model
â”œâ”€â”€ datasets/                   # Dataset directory
â”‚   â”œâ”€â”€ coco/                  # COCO dataset
â”‚   â””â”€â”€ coco128-seg/           # Smaller test dataset
â”œâ”€â”€ runs/                      # Training/validation results
â”‚   â””â”€â”€ segment/               # Segmentation results
â”œâ”€â”€ finetune/                  # Fine-tuning results
â”œâ”€â”€ repo/                      # Ultralytics repository
â”‚   â””â”€â”€ ultralytics/           # Modified ultralytics code
â””â”€â”€ yolov8_2/                  # Virtual environment
```

## ğŸ“Š Monitoring and Evaluation

The project tracks:
- Model size reduction (parameters and MACs)
- Performance metrics (box mAP, mask mAP)
- Inference speed improvements
- Training convergence during fine-tuning

## ğŸ“š References

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [Torch-Pruning](https://github.com/VainF/Torch-Pruning)

## ğŸ“ License

This project is based on Ultralytics YOLO which uses AGPL-3.0 License.

